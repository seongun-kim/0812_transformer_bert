{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_qNSzzyaCbD"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "jmjh290raIky"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J0Qjg6vuaHNt"
   },
   "source": [
    "# Transformer를 이용하여 포르투갈어를 영어로 번역하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Attention Is All You Need\" 논문이 제안한 Transformer 이용해 포르투갈어를 영어로 바꾸는 모델을 학습합니다.\n",
    "\n",
    "Transformer의 핵심 아이디어는 self-attention입니다. self-attention은 입력 시퀀스의 벡터 표현을 계산하기 위해 입력 시퀀스 단어의 여러 위치에 대해 attention을 계산합니다. Transformer는 여러겹의 self-attention 층으로 구성되어 있고 \"scaled- dot product attention\", \"Multi-head attention\"에서 자세히 설명할 것입니다.\n",
    "\n",
    "Transformer의 장점과 단점은 다음과 같습니다.\n",
    "\n",
    "장점\n",
    "\n",
    "* 모든 층들이 parallel하게 계산됩니다. Transformer는 모든 연산을 matrix 형태로 한 번에 처리할 수 있지만 RNN의 경우에는 매 time-step마다 순서대로 출력값을 계산하기 때문에 연산의 효율성이 떨어집니다.\n",
    "* 멀리 떨어져 있는 입력 값도 모든 출력 값에 영향을 줄 수 있습니다. RNN의 경우는 멀리 떨어져 있는 입력 값에 대한 영향이 점점 떨어지기 때문에 long-range dependency를 학습하기 힘듭니다. 하지만 Transformer는 아무리 멀리 떨어져 있어도 그 입력에 대한 attention을 계산할 수 있기 때문에 long-range dependency를 훨씬 잘 학습할 수 있습니다. \n",
    "\n",
    "단점\n",
    "\n",
    "* 시계열 데이터의 경우 특정 time-step의 출력값이 항상 모든 과거 정보를 이용해 계산되기 때문에 최근 값이 더 중요한 경우에 대해서는 효율성이 떨어질 수도 있습니다. 최근이 중요함에도 불구하고 계속 전체 과거 정보를 이용하기 때문입니다.\n",
    "\n",
    "\n",
    "<img src=\"./images/attention_map_portuguese.png\" width=\"800\" alt=\"Attention heatmap\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JjJJyJTZYebt"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fd1NWMxjfsDd"
   },
   "source": [
    "## 입력 파이프라인 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t4_Qt8W1hJE_"
   },
   "source": [
    "\"tensorflow_datasets\"를 이용해 포르투갈어에서 영어로 번역하는 데이터셋을 불러옵니다. 이 데이터셋은 약 50000개의 훈련 데이터와 1100개의 검증 데이터, 2000개의 테스트 데이터로 구성되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8q9t4FmN96eN",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
    "                               as_supervised=True)\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RCEKotqosGfq"
   },
   "source": [
    "훈련 데이터셋에서 subword tokenizer를 생성합니다. tokenizer는 문장을 단어별로 분리해주는 역할을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KVBg5Q8tBk5z"
   },
   "outputs": [],
   "source": [
    "tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
    "\n",
    "tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4DYWukNFkGQN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [7915, 1248, 7946, 7194, 13, 2799, 7877]\n",
      "The original string: Transformer is awesome.\n"
     ]
    }
   ],
   "source": [
    "sample_string = 'Transformer is awesome.'\n",
    "\n",
    "tokenized_string = tokenizer_en.encode(sample_string)\n",
    "print ('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer_en.decode(tokenized_string)\n",
    "print ('The original string: {}'.format(original_string))\n",
    "\n",
    "assert original_string == sample_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o9KJWJjrsZ4Y"
   },
   "source": [
    "tokenizer는 문장을 subword 단위로 encoding 합니다. 만일 단어가 tokenizer의 dictionary에 없으면 더 작은 단위로 쪼갭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bf2ntBxjkqK6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7915 ----> T\n",
      "1248 ----> ran\n",
      "7946 ----> s\n",
      "7194 ----> former \n",
      "13 ----> is \n",
      "2799 ----> awesome\n",
      "7877 ----> .\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "  print ('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bcRp7VcQ5m6g"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8087\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer_en.vocab_size) # word index: 0~8086"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kGi4PoVakxdc"
   },
   "source": [
    "모델에 문장의 시작과 끝을 알려주기 위해 start token과 end token을 추가합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UZwnPr4R055s"
   },
   "outputs": [],
   "source": [
    "# start token: 8087, end token: 8088\n",
    "def encode(lang1, lang2):\n",
    "  lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n",
    "      lang1.numpy()) + [tokenizer_pt.vocab_size+1]\n",
    "\n",
    "  lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
    "      lang2.numpy()) + [tokenizer_en.vocab_size+1]\n",
    "  \n",
    "  return lang1, lang2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tx1sFbR-9fRs"
   },
   "source": [
    "`Dataset.map` 을 이용해 'encode' 함수를 적용해야 하지만 `Dataset.map`은 graph mode에서만 작동합니다. \n",
    "\n",
    "* 그래프 텐서는 값을 가지지 않습니다. 그래프만 만들고 나중에 값을 대입합니다.\n",
    "* 그래프 모드에서는 Tensorflow에 내장되어 있는 연산이나 함수만 쓸 수 있습니다.\n",
    "\n",
    "따라서 '.map'을 이용해 'encode' 함수를 바로 적용할 수 없습니다. `tf.py_function`을 이용해 'encode'함수를 감싸야 합니다. `tf.py_function`는 텐서를 'encode' 함수의 입력값으로 쓰일 수 있도록 해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mah1cS-P70Iz"
   },
   "outputs": [],
   "source": [
    "def tf_encode(pt, en):\n",
    "  result_pt, result_en = tf.py_function(encode, [pt, en], [tf.int64, tf.int64])\n",
    "  result_pt.set_shape([None])\n",
    "  result_en.set_shape([None])\n",
    "\n",
    "  return result_pt, result_en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6JrGp5Gek6Ql"
   },
   "source": [
    "학습 속도를 올리기 위해 토큰 길이가 40을 넘는 예제는 버립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2QEgbjntk6Yf"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c081xPGv1CPI"
   },
   "outputs": [],
   "source": [
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "  return tf.logical_and(tf.size(x) <= max_length,\n",
    "                        tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9mk9AZdZ5bcS"
   },
   "outputs": [],
   "source": [
    "# sos + encoded tocken + eos\n",
    "train_dataset = train_examples.map(tf_encode)\n",
    "# 토큰 길이 40 이상의 토큰 필터링\n",
    "train_dataset = train_dataset.filter(filter_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding 후, sos, eos가 잘 붙었는지, 토큰 길이가 40 미만인지 dataset을 확인합니다.\n",
    "iterator = iter(train_dataset)\n",
    "for i in range(10):\n",
    "    pt, en = iterator.get_next()\n",
    "    print('idx of data: {}\\npt shape: {}\\npt data: {}\\nen shape: {}\\nen data: {}\\n'.format(i, pt.shape, pt, en.shape, en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9mk9AZdZ5bcS"
   },
   "outputs": [],
   "source": [
    "# cache the dataset to memory to get a speedup while reading from it.\n",
    "train_dataset = train_dataset.cache()\n",
    "\n",
    "# 배치로 학습하기 위해서는 문장의 길이를 같게 해야 합니다. 하지만 실제 입력 문장의 길이는 모두 다릅니다.\n",
    "# 따라서 배치 안에서 동일한 문장 길이를 유지하기 위해 padding을 합니다 보통 문장 뒤에 0을 삽입하여\n",
    "# 문장의 길이를 맞춰줍니다.\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9mk9AZdZ5bcS"
   },
   "outputs": [],
   "source": [
    "# Optional\n",
    "# prefetch를 함으로써 현재 batch를 processing 하는동안 다음 batch를 준비합니다.\n",
    "# 이 과정은 추가적인 메모리를 요구하지만, latency와 throughput을 높여줍니다.\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9mk9AZdZ5bcS"
   },
   "outputs": [],
   "source": [
    "# Validation dataset에도 똑같은 전처리 과정을 적용합니다.\n",
    "val_dataset = val_examples.map(tf_encode)\n",
    "val_dataset = val_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_fXvfYVfQr2n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 38), dtype=int64, numpy=\n",
       " array([[8214,  342, 3032, ...,    0,    0,    0],\n",
       "        [8214,   95,  198, ...,    0,    0,    0],\n",
       "        [8214, 4479, 7990, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8214,  584,   12, ...,    0,    0,    0],\n",
       "        [8214,   59, 1548, ...,    0,    0,    0],\n",
       "        [8214,  118,   34, ...,    0,    0,    0]])>,\n",
       " <tf.Tensor: shape=(64, 40), dtype=int64, numpy=\n",
       " array([[8087,   98,   25, ...,    0,    0,    0],\n",
       "        [8087,   12,   20, ...,    0,    0,    0],\n",
       "        [8087,   12, 5453, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8087,   18, 2059, ...,    0,    0,    0],\n",
       "        [8087,   16, 1436, ...,    0,    0,    0],\n",
       "        [8087,   15,   57, ...,    0,    0,    0]])>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size: 64\n",
    "# 배치 안의 가장 긴 문장의 길이로 일치시켜줍니다.\n",
    "# pt_batch의 경우는 첫번째 배치의 가장 긴 문장의 길이가 38이고,\n",
    "# en_batch의 경우는 첫번째 배치의 가장 긴 문장의 길이가 40입니다.\n",
    "# 배치별로 가장 긴 문장의 길이는 모두 다르기 때문에 2번째 차원은 배치별로 다를 것입니다.\n",
    "\n",
    "pt_batch, en_batch = next(iter(val_dataset))\n",
    "pt_batch, en_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nBQuibYA4n0n"
   },
   "source": [
    "## Positional encoding\n",
    "\n",
    "Transformer는 문장을 순서대로 넣는 것이 아니라 한 번에 병렬로 처리하기 때문에 단어의 순서에 대한 정보가 별도로 주어져야 합니다. Embedding vector에 positional encoding vector를 더해 줌으로써 한 문장 내의 단어들의 위치에 대한 정보를 추가합니다. Embedding vector는 단어들의 상대적인 위치를 반영하지 않습니다. Positional encoding을 통해 embedding space에서 문장 내에 거리가 가까운 단어들이 좀 더 비슷한 vector를 가지도록 조정합니다. 즉, 같은 의미의 단어가 문장 내에서 가까운 위치에 존재할 때 embedding vector는 비슷한 값을 가지고, 같은 의미의 단어라 할지라도 문장 내에서 먼 위치에 존재하면 embedding vector의 값은 달라지게 됩니다.\n",
    "\n",
    "<img src=\"./images/positional_encoding(1).png\" width=\"500\" alt=\"scaled_dot_product_attention\">\n",
    "\n",
    "<img src=\"./images/positional_encoding(2).png\" width=\"250\" alt=\"scaled_dot_product_attention\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nBQuibYA4n0n"
   },
   "source": [
    "Positional encoding을 위해 다음의 두 함수를 사용합니다.\n",
    "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
    "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WhIOZjMNKujn"
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Rz82wEs5biZ"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "  # apply sin to even indices in the array; 2i\n",
    "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "  # apply cos to odd indices in the array; 2i+1\n",
    "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "  pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1kLCla68EloE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512) # (1, 50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a_b4ou4TYqUN"
   },
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s42Uydjkv0hF"
   },
   "source": [
    "같은 배치내에 있는 문장의 길이를 일치시키기 위해 padding을 이용했습니다. 하지만 이는 실제 입력이 아니기 때문에 입력에서 padding을 제거해야 합니다. masking을 이용해 padding을 가려줌으로써 모델이 padding을 입력으로 인식하지 못하도록 합니다. 여기서 padding에 해당하는 숫자는 0입니다. 따라서 0이 나타나는 부분을 masking을 이용해 가려줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U2i8-e1s8ti9"
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # 추후 multi-head attention에 이를 이용할 것이므로 차원 2개를 중간에 추가해줍니다. \n",
    "\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A7BYeBCNvi7n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# masking으로 가리는 부분을 1, 아니면 0\n",
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z0hzukDBgVom"
   },
   "source": [
    "번역 결과를 학습하기 위해서는 타겟 이전의 단어들만 고려해야 합니다. 그 이유는 학습 후에 번역된 문장을 만들기 위해서는 단어를 앞에서부터 뒤로 순서대로 생성해야 하기 때문입니다. 즉 앞에서 뒤로 단어를 순서대로 만들 수 있는 모델을 학습하기 위해서는 타겟 이후의 단어들을 고려하면 안 됩니다. 예를 들면 세 번째 단어를 예측하기 위해서는 첫 번재, 두 번째 단어만을 보고 예측합니다. 따라서 네 번째, 그리고 그 이후의 단어들을 가려야 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dVxS8OPI9uI0"
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "  return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yxKGuXxaBeeE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# masking으로 가리는 부분을 1, 아니면 0\n",
    "x = tf.random.uniform((1, 3))\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xluDl5cXYy4y"
   },
   "source": [
    "## Scaled dot product attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vsxEE_-Wa1gF"
   },
   "source": [
    "<img src=\"./images/scaled_attention.png\" width=\"500\" alt=\"scaled_dot_product_attention\">\n",
    "\n",
    "Attention을 계산하기 위해서는 Q (query), K (key), V (value) 세 가지 요소가 필요합니다. 다음의 식을 이용해 attention을 계산합니다.\n",
    "\n",
    "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$\n",
    "\n",
    "Dot-product attention을 계산할 때 sqrt(d_k)로 나눠줍니다. 그 이유는 d_k가 커질수록 dot-product의 값의 분산도 커지기 때문입니다. 이는 softmax 함수가 작은 값들을 무시할 가능성이 커지고 그 결과 dot-product의 값이 작은 부분에 gradient가 흐르지 않게 됩니다.  \n",
    "\n",
    "예를 들면 'Q', 'K' 가 평균 0 분산 1를 가진다고 가정합니다. 두 matrix의 행렬 곱의 값은 평균 0 분산 d_k를 가집니다. 따라서 sqrt(d_k)는 'Q', 'K'의 행렬 곱의 값이 평균 0 분산 1로 만들어주는 역할을 합니다. 따라서 좀 더 부드러운 softmax 값을 기대할 수 있습니다.\n",
    "\n",
    "Mask 에는 음의 무한대와 가까운 -1e9 값을 곱해줍니다. Q, K의 행렬 곱 값이 음의 무한대와 가까우면 softmax시에 0에 가까운 값이 될 것이기 때문에 masking된 부분을 무시하는 효과를 얻을 수 있습니다. 만일 masking 되는 부분에 이 값을 곱하지 않으면 Q, K의 행렬 곱 결과가 masking 되는 부분에 0이 될텐데 이는 softmax 후에 0이 되지 않을 가능성이 큽니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LazzUq3bJ5SH"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "\n",
    "\n",
    "  '''\n",
    "  attention weight 계산\n",
    "  seq_len_k = seq_len_v.\n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "\n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "  '''\n",
    "  # transpose_a=True => 첫 번째 matrix의 마지막 두 차원이 transpose됨\n",
    "  # transpose_b=True => 두 번째 matrix의 마지막 두 차원이 transpose됨\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # matmul_qk: (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  # tf.cast: 입력을 텐서로 바꿔줌\n",
    "  # scale matmul_qk\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # mask 된 부분에 -1e9를 더해줌 => softmax 후 0이 됨.\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiqETnhCkoXh"
   },
   "source": [
    "softmax 함수가 attention_weights의 마지막 축 seq_len_k 방향으로 합이 1이 되도록 계산되었기 때문에 각 Q에 대한 K의 중요도를 의미합니다.\n",
    "\n",
    "즉 output은 각 Q에 대해 중요한 V만을 남기고 필요없는 V는 버릴 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n90YjClyInFy"
   },
   "outputs": [],
   "source": [
    "def print_out(q, k, v):\n",
    "  temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, None)\n",
    "  print ('Attention weights are:')\n",
    "  print (temp_attn)\n",
    "  print ('Output is:')\n",
    "  print (temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yAzUAf2DPlNt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "# This `query` aligns with the second `key`,\n",
    "# so the second `value` is returned.\n",
    "\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "\n",
    "# output; 0 * [1,0] + 1 * [10,0] + 0 * [100,5] + 0 * [1000, 6]\n",
    "# 주어진 q에 대해 중요한 v만 남긴 결과가 output으로 나옵니다.\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zg6k-fGhgXra"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 즉 output은 temp_v의 row vector를 attention weight에 의해 weighted average 된 값이라고 할 수 있습니다.\n",
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
    "# output: 0 * [1,0] + 0 * [10,0] + 0.5 * [100,5] + 0.5 * [1000, 6]\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UAq3YOzUgXhb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns equally with the first and second key, \n",
    "# so their values get averaged.\n",
    "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "# output: 0.5 * [1,0] + 0.5 * [10,0] + 0 * [100,5] + 0 * [1000, 6]\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aOz-4_XIhaTP"
   },
   "source": [
    "이제까지는 q에 대해 각각 output을 계산했는데 이번에는 q들을 묶어서 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6dlU8Tm-hYrF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kmzGPEy64qmA"
   },
   "source": [
    "## Multi-head attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fz5BMC8Kaoqo"
   },
   "source": [
    "<img src=\"./images/multi_head_attention.png\" width=\"500\" alt=\"multi-head attention\">\n",
    "\n",
    "\n",
    "Multi-head attention은 다음 4가지 부분으로 구성되어 있습니다:\n",
    "*    Linear layers and split into heads.\n",
    "*    Scaled dot-product attention.\n",
    "*    Concatenation of heads.\n",
    "*    Final linear layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JPmbr6F1C-v_"
   },
   "source": [
    "multi-head attention에는 Q (query), K (key), V (value) 세 가지가 입력으로 들어갑니다. 이 입력들은 linear (Dense) layer를 통과한 후 multiple head로 쪼갭니다 (multi-head attention).\n",
    "\n",
    "각 head 별로 `scaled_dot_product_attention`을 계산합니다. 여러 head에서 계산된 attention output은 concatenation이 됩니다. 그 다음 linear (Dense) layer를 통과합니다.\n",
    "\n",
    "여러 head을 이용해 attention output을 계산하는 이유는 서로 다른 시점의 중요한 정보를 뽑아낼 수 있고 이 정보들을 통해 모델의 학습 능력을 향상시킬 수 있기 때문입니다. \n",
    "\n",
    "여러 head로 쪼개지 않고 하나의 attention output을 계산하는 것과 여러 head을 이용해 여러 개의 attention output을 계산하는 것은 연산량에 있어서 차이가 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSV3PPKsYecw"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "    \n",
    "    assert d_model % self.num_heads == 0 # d_model 길이의 vector를 num_heads 만큼 쪼개야 하기 때문에 나누어 떨어져야합니다.\n",
    "    \n",
    "    self.depth = d_model // self.num_heads\n",
    "    \n",
    "    self.wq = tf.keras.layers.Dense(d_model) # d_model: 출력 값의 차원, query를 계산하는데 쓰임\n",
    "    self.wk = tf.keras.layers.Dense(d_model) # d_model: 출력 값의 차원, key를 계산하는데 쓰임\n",
    "    self.wv = tf.keras.layers.Dense(d_model) # d_model: 출력 값의 차원, value를 계산하는데 쓰임\n",
    "    \n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "  def split_heads(self, x, batch_size):\n",
    "    \n",
    "    # d_model을 num_heads * depth 로 쪼갭니다.\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "    \n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "    \n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "    \n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "    \n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "    \n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "    \n",
    "    # num_head 만큼의 attention output을 concatenation 합니다.\n",
    "    concat_attention = tf.reshape(scaled_attention, \n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model), d_model=num_heads*depth\n",
    "\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0D8FJue5lDyZ"
   },
   "source": [
    "Create a `MultiHeadAttention` layer to try out. At each location in the sequence, `y`, the `MultiHeadAttention` runs all 8 attention heads across all other locations in the sequence, returning a new vector of the same length at each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hu94p-_-2_BX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(v=y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape\n",
    "# 총 8개의 attention weight가 생성됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RdDqGayx67vv"
   },
   "source": [
    "## Point wise feed forward network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gBqzJXGfHK3X"
   },
   "source": [
    "Point wise feed forward network는 두 개의 fully-connected layer (linear, dense layer) 와 ReLU 활성화 함수로 구성되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ET7xLt0yCT6Z"
   },
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mytb1lPyOHLB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7e7hKcxn6-zd"
   },
   "source": [
    "## Encoder and decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yScbC0MUH8dS"
   },
   "source": [
    "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/transformer.png\" width=\"600\" alt=\"transformer\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QFv-FNYUmvpn"
   },
   "source": [
    "### Encoder layer\n",
    "\n",
    "각 encoder layer는 두 개의 sublayer로 구성되어 있습니다.\n",
    "\n",
    "1.   Multi-head attention (with padding mask) \n",
    "2.    Point wise feed forward networks. \n",
    "\n",
    "각각의 sublayer들은 residual connection 과 layer normalization을 차례대로 적용합니다. residual connection은 신경망의 gradient 소실 문제를 해결할 수 있습니다.\n",
    "\n",
    "각 sublayer의 output은 `LayerNorm(x + Sublayer(x))`로 계산됩니다. normalization은 `d_model` (last) axis 방향으로 이루어집니다. N개의 encoder가 쌓여서 하나의 전체 encoder layer를 구성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ncyS-Ms3i2x_"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AzZRXdO0mI48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6LO_48Owmx_o"
   },
   "source": [
    "### Decoder layer\n",
    "\n",
    "각각 decoder layer를 다음 sublayer로 구성되어 있습니다.\n",
    "\n",
    "\n",
    "1.   Masked multi-head attention (with look ahead mask and padding mask), decoder의 입력은 영어 문장이 들어갑니다. 학습 과정에서는 전체 문장이 입력값으로 들어가는데 문장의 다음 단어를 예측하기 위해서는 이전 단어들만 보고 예측해야 합니다. 따라서 이후 단어들에 대해서는 masking을 통해 가려줍니다. (look ahead mask).\n",
    "2.   Multi-head attention (with padding mask). V (value) and K (key)는 encoder의 출력값을 이용하고, Q (query)는 decoder의 multi-head self attention의 출력 값을 이용합니다.\n",
    "3.   Point wise feed forward networks\n",
    "\n",
    "각 sublayer의 output은 LayerNorm(x + Sublayer(x))로 계산됩니다. normalization은 d_model (last) axis 방향으로 이루어집니다. N개의 decoder가 쌓여서 하나의 전체 decoder layer를 구성합니다.\n",
    "\n",
    "V, K는 encoder의 출력값, Q는 decoder의 multi-head self attention 출력값을 이용하기 때문에 attention weights는 주어진 decoder 입력값에 대한 encoder 출력값의 중요도를 의미합니다. 즉, decoder는 다음 단어를 encoder의 출력값과 decoder의 self-attention을 이용하여 예측합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9SoX0-vd1hue"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "   \n",
    "    # 표준편차가 0이 되는 경우에 에러가 나기 때문에 표준편차에 epsilon를 더해줍니다.\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6) \n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn1 = self.dropout1(attn1, training=training)\n",
    "    out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "    # encoder의 출력값이 key, value에 들어갑니다.\n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn2 = self.dropout2(attn2, training=training)\n",
    "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ne2Bqx8k71l0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SE1H51Ajm0q1"
   },
   "source": [
    "### Encoder\n",
    "\n",
    "`Encoder`의 구성요소는 다음과 같습니다.\n",
    "1.   Input Embedding\n",
    "2.   Positional Encoding\n",
    "3.   N encoder layers\n",
    "\n",
    "입력 embedding 과 positional encoding을 더합니다. 더한 값을 N개의 encoder layer의 입력값으로 이용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jpEox7gJ8FCI"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                            self.d_model)\n",
    "    \n",
    "    \n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "  \n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    \n",
    "    # adding embedding and position encoding.\n",
    "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "    \n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "    return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8QG9nueFQKXx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, input_vocab_size=8500,\n",
    "                         maximum_position_encoding=10000)\n",
    "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
    "\n",
    "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p-uO6ls8m2O5"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZtT7PKzrXkNr"
   },
   "source": [
    "`Decoder`의 구성 요소는 다음과 같습니다.\n",
    "1.   Output Embedding, 번역 결과가 되는 영어 문장에 대한 embedding입니다.\n",
    "2.   Positional Encoding \n",
    "3.   N decoder layers\n",
    "\n",
    "타겟인 영어 문장이 decoder의 입력값으로 들어가기 때문이 이 또한 positional encoding이 필요합니다. decoder의 최종 출력값을 결과를 예측하는 마지막 layer의 입력값으로 들어갑니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d5_d5-PLQXwY"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "    \n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "    \n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "    \n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "      \n",
    "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a1jXoAMRZyvu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, target_vocab_size=8000,\n",
    "                         maximum_position_encoding=5000)\n",
    "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "output, attn = sample_decoder(temp_input, \n",
    "                              enc_output=sample_encoder_output, \n",
    "                              training=False,\n",
    "                              look_ahead_mask=None, \n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y54xnJnuYgJ7"
   },
   "source": [
    "## Transformer 생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uERO1y54cOKq"
   },
   "source": [
    "Transformer는 encoder, decoder, 최종 linear layer로 구성됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PED3bIpOYkBu"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                           input_vocab_size, pe_input, rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                           target_vocab_size, pe_target, rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "  def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "    \n",
    "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    dec_output, attention_weights = self.decoder(\n",
    "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "    \n",
    "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "    \n",
    "    return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tJ4fbQcIkHW1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 36, 8000])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
    "    input_vocab_size=8500, target_vocab_size=8000, \n",
    "    pe_input=10000, pe_target=6000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "                               enc_padding_mask=None, \n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wsINyf1VEQLC"
   },
   "source": [
    "## hyperparameter 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zVjWCxFNcgbt"
   },
   "source": [
    "모델의 크기를 줄이고 학습 속도를 키우기 위해 *num_layers, d_model, dff* 가 작아야 합니다.\n",
    "\n",
    "*num_layers=6*, *d_model = 512*, *dff = 2048*. 은 \"attention is all you need\" 논문의 base model에 해당합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lnJn5SLA2ahP"
   },
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = tokenizer_pt.vocab_size + 2 # start, end token이 추가되었기 때문에 2가 더해집니다.\n",
    "target_vocab_size = tokenizer_en.vocab_size + 2 # start, end token이 추가되었기 때문에 2가 더해집니다.\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xYEGhEOtzn5W"
   },
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GOmWW--yP3zx"
   },
   "source": [
    "Adam optimizer와 다음 learning rate scheduler를 이용합니다.\n",
    "\n",
    "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYQdOO1axwEI"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    \n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "    \n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7r4scdulztRx"
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f33ZCgvHpPdG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YgkDE7hzo8r5"
   },
   "source": [
    "## Loss and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oxGJtoDuYIHL"
   },
   "source": [
    "타겟 시퀀스에 padding이 있기 때문에 loss를 계산할때는 padding 부분을 제거해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MlhsJMm0TW_B"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none') \n",
    "# from_logits=True: y_pred가 확률분포인 경우\n",
    "# reduction='none': cross entropy loss를 각각 계산한 후 더하지 않음 (추후 padding 0에 해당하는 loss를 없애기 위해)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "67oqVHiT0Eiu"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask # padding 0에 해당하는 loss 제거\n",
    "  \n",
    "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "phlyxMnm-Tpx"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aeHumfr7zmMa"
   },
   "source": [
    "## 학습 및 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UiysUa--4tOU"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZOJUSB1T8GjM"
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "  # Encoder padding mask\n",
    "  enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 2nd attention block in the decoder.\n",
    "  # This padding mask is used to mask the encoder outputs.\n",
    "  dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 1st attention block in the decoder.\n",
    "  # It is used to pad and mask future tokens in the input received by \n",
    "  # the decoder.\n",
    "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "  dec_target_padding_mask = create_padding_mask(tar)\n",
    "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "  return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fzuf06YZp66w"
   },
   "source": [
    "checkpoint 경로와 checkpoint manager를 생성합니다. 매 `n` epoch 마다 모델이 저장됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hNhuYfllndLZ"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "# max_to_keep: 저장되는 checkpoint 수\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Di_Yaa1gf9r"
   },
   "source": [
    "타겟은 tar_inp과 tar_real로 나누어집니다. tar_inp은 decoder의 입력값이고 `tar_real`은 tar_inp에서 오른쪽으로 한 칸 이동한 값입니다. Transformer의 출력값이 `tar_real`이 되도록 학습합니다. 즉 현재 단어가 주어졌을 때 바로 다음 단어를 예측하는 모델을 생성합니다.\n",
    "\n",
    "\n",
    "예를 들면, `sentence` = \"SOS A lion in the jungle is sleeping EOS\" (SOS: start of sentence, start token, EOS: end of sentence, end token)\n",
    "\n",
    "`tar_inp` =  \"SOS A lion in the jungle is sleeping\"\n",
    "\n",
    "`tar_real` = \"A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "모델이 미래 단어를 보는 것을 막기 위해 `look-ahead mask`를 이용해 미래 단어를 가립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LKpoA6q1sJFj"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJwmp9OE29oj"
   },
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "  tar_inp = tar[:, :-1]\n",
    "  tar_real = tar[:, 1:]\n",
    "  \n",
    "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "\n",
    "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "  train_loss(loss)\n",
    "  train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qM2PDWGDJ_8V"
   },
   "source": [
    "포르투갈어가 입력 언어, 영어가 타겟 언어입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bbvmaKNiznHZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 9.0300 Accuracy 0.0000\n",
      "Epoch 1 Batch 50 Loss 8.9656 Accuracy 0.0002\n",
      "Epoch 1 Batch 100 Loss 8.8644 Accuracy 0.0118\n",
      "Epoch 1 Batch 150 Loss 8.7545 Accuracy 0.0169\n",
      "Epoch 1 Batch 200 Loss 8.6253 Accuracy 0.0194\n",
      "Epoch 1 Batch 250 Loss 8.4694 Accuracy 0.0209\n",
      "Epoch 1 Batch 300 Loss 8.2909 Accuracy 0.0222\n",
      "Epoch 1 Batch 350 Loss 8.1037 Accuracy 0.0259\n",
      "Epoch 1 Batch 400 Loss 7.9231 Accuracy 0.0304\n",
      "Epoch 1 Batch 450 Loss 7.7577 Accuracy 0.0340\n",
      "Epoch 1 Batch 500 Loss 7.6120 Accuracy 0.0371\n",
      "Epoch 1 Batch 550 Loss 7.4777 Accuracy 0.0402\n",
      "Epoch 1 Batch 600 Loss 7.3549 Accuracy 0.0435\n",
      "Epoch 1 Batch 650 Loss 7.2385 Accuracy 0.0470\n",
      "Epoch 1 Batch 700 Loss 7.1263 Accuracy 0.0503\n",
      "Epoch 1 Loss 7.1222 Accuracy 0.0504\n",
      "Time taken for 1 epoch: 79.51124024391174 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 5.6310 Accuracy 0.0959\n",
      "Epoch 2 Batch 50 Loss 5.5325 Accuracy 0.1017\n",
      "Epoch 2 Batch 100 Loss 5.4508 Accuracy 0.1050\n",
      "Epoch 2 Batch 150 Loss 5.3913 Accuracy 0.1079\n",
      "Epoch 2 Batch 200 Loss 5.3371 Accuracy 0.1103\n",
      "Epoch 2 Batch 250 Loss 5.2959 Accuracy 0.1122\n",
      "Epoch 2 Batch 300 Loss 5.2539 Accuracy 0.1140\n",
      "Epoch 2 Batch 350 Loss 5.2188 Accuracy 0.1155\n",
      "Epoch 2 Batch 400 Loss 5.1809 Accuracy 0.1171\n",
      "Epoch 2 Batch 450 Loss 5.1483 Accuracy 0.1185\n",
      "Epoch 2 Batch 500 Loss 5.1160 Accuracy 0.1201\n",
      "Epoch 2 Batch 550 Loss 5.0873 Accuracy 0.1216\n",
      "Epoch 2 Batch 600 Loss 5.0600 Accuracy 0.1229\n",
      "Epoch 2 Batch 650 Loss 5.0332 Accuracy 0.1242\n",
      "Epoch 2 Batch 700 Loss 5.0086 Accuracy 0.1251\n",
      "Epoch 2 Loss 5.0081 Accuracy 0.1251\n",
      "Time taken for 1 epoch: 42.47013020515442 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 4.8852 Accuracy 0.1370\n",
      "Epoch 3 Batch 50 Loss 4.6121 Accuracy 0.1434\n",
      "Epoch 3 Batch 100 Loss 4.5931 Accuracy 0.1443\n",
      "Epoch 3 Batch 150 Loss 4.5789 Accuracy 0.1449\n",
      "Epoch 3 Batch 200 Loss 4.5663 Accuracy 0.1448\n",
      "Epoch 3 Batch 250 Loss 4.5567 Accuracy 0.1452\n",
      "Epoch 3 Batch 300 Loss 4.5414 Accuracy 0.1457\n",
      "Epoch 3 Batch 350 Loss 4.5283 Accuracy 0.1464\n",
      "Epoch 3 Batch 400 Loss 4.5230 Accuracy 0.1467\n",
      "Epoch 3 Batch 450 Loss 4.5109 Accuracy 0.1474\n",
      "Epoch 3 Batch 500 Loss 4.4999 Accuracy 0.1483\n",
      "Epoch 3 Batch 550 Loss 4.4892 Accuracy 0.1490\n",
      "Epoch 3 Batch 600 Loss 4.4756 Accuracy 0.1499\n",
      "Epoch 3 Batch 650 Loss 4.4601 Accuracy 0.1506\n",
      "Epoch 3 Batch 700 Loss 4.4481 Accuracy 0.1514\n",
      "Epoch 3 Loss 4.4476 Accuracy 0.1514\n",
      "Time taken for 1 epoch: 43.053940534591675 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 4.1151 Accuracy 0.1710\n",
      "Epoch 4 Batch 50 Loss 4.1348 Accuracy 0.1659\n",
      "Epoch 4 Batch 100 Loss 4.1419 Accuracy 0.1659\n",
      "Epoch 4 Batch 150 Loss 4.1288 Accuracy 0.1662\n",
      "Epoch 4 Batch 200 Loss 4.1144 Accuracy 0.1674\n",
      "Epoch 4 Batch 250 Loss 4.1020 Accuracy 0.1684\n",
      "Epoch 4 Batch 300 Loss 4.0868 Accuracy 0.1692\n",
      "Epoch 4 Batch 350 Loss 4.0697 Accuracy 0.1702\n",
      "Epoch 4 Batch 400 Loss 4.0547 Accuracy 0.1715\n",
      "Epoch 4 Batch 450 Loss 4.0377 Accuracy 0.1725\n",
      "Epoch 4 Batch 500 Loss 4.0207 Accuracy 0.1737\n",
      "Epoch 4 Batch 550 Loss 4.0057 Accuracy 0.1748\n",
      "Epoch 4 Batch 600 Loss 3.9927 Accuracy 0.1758\n",
      "Epoch 4 Batch 650 Loss 3.9799 Accuracy 0.1768\n",
      "Epoch 4 Batch 700 Loss 3.9649 Accuracy 0.1776\n",
      "Epoch 4 Loss 3.9644 Accuracy 0.1777\n",
      "Time taken for 1 epoch: 42.085126876831055 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 3.5290 Accuracy 0.1827\n",
      "Epoch 5 Batch 50 Loss 3.6251 Accuracy 0.1942\n",
      "Epoch 5 Batch 100 Loss 3.6223 Accuracy 0.1935\n",
      "Epoch 5 Batch 150 Loss 3.6125 Accuracy 0.1954\n",
      "Epoch 5 Batch 200 Loss 3.6083 Accuracy 0.1962\n",
      "Epoch 5 Batch 250 Loss 3.6035 Accuracy 0.1967\n",
      "Epoch 5 Batch 300 Loss 3.5873 Accuracy 0.1974\n",
      "Epoch 5 Batch 350 Loss 3.5775 Accuracy 0.1985\n",
      "Epoch 5 Batch 400 Loss 3.5696 Accuracy 0.1996\n",
      "Epoch 5 Batch 450 Loss 3.5578 Accuracy 0.2003\n",
      "Epoch 5 Batch 500 Loss 3.5451 Accuracy 0.2010\n",
      "Epoch 5 Batch 550 Loss 3.5352 Accuracy 0.2019\n",
      "Epoch 5 Batch 600 Loss 3.5264 Accuracy 0.2024\n",
      "Epoch 5 Batch 650 Loss 3.5143 Accuracy 0.2031\n",
      "Epoch 5 Batch 700 Loss 3.5030 Accuracy 0.2039\n",
      "Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-1\n",
      "Epoch 5 Loss 3.5030 Accuracy 0.2038\n",
      "Time taken for 1 epoch: 42.5210440158844 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 3.3898 Accuracy 0.1991\n",
      "Epoch 6 Batch 50 Loss 3.1926 Accuracy 0.2164\n",
      "Epoch 6 Batch 100 Loss 3.1816 Accuracy 0.2183\n",
      "Epoch 6 Batch 150 Loss 3.1802 Accuracy 0.2188\n",
      "Epoch 6 Batch 200 Loss 3.1792 Accuracy 0.2194\n",
      "Epoch 6 Batch 250 Loss 3.1762 Accuracy 0.2203\n",
      "Epoch 6 Batch 300 Loss 3.1721 Accuracy 0.2203\n",
      "Epoch 6 Batch 350 Loss 3.1627 Accuracy 0.2212\n",
      "Epoch 6 Batch 400 Loss 3.1577 Accuracy 0.2214\n",
      "Epoch 6 Batch 450 Loss 3.1494 Accuracy 0.2217\n",
      "Epoch 6 Batch 500 Loss 3.1436 Accuracy 0.2223\n",
      "Epoch 6 Batch 550 Loss 3.1349 Accuracy 0.2234\n",
      "Epoch 6 Batch 600 Loss 3.1266 Accuracy 0.2239\n",
      "Epoch 6 Batch 650 Loss 3.1188 Accuracy 0.2248\n",
      "Epoch 6 Batch 700 Loss 3.1118 Accuracy 0.2253\n",
      "Epoch 6 Loss 3.1114 Accuracy 0.2253\n",
      "Time taken for 1 epoch: 41.51395559310913 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 2.7872 Accuracy 0.2512\n",
      "Epoch 7 Batch 50 Loss 2.8136 Accuracy 0.2407\n",
      "Epoch 7 Batch 100 Loss 2.7953 Accuracy 0.2398\n",
      "Epoch 7 Batch 150 Loss 2.7870 Accuracy 0.2412\n",
      "Epoch 7 Batch 200 Loss 2.7844 Accuracy 0.2414\n",
      "Epoch 7 Batch 250 Loss 2.7716 Accuracy 0.2420\n",
      "Epoch 7 Batch 300 Loss 2.7682 Accuracy 0.2425\n",
      "Epoch 7 Batch 350 Loss 2.7660 Accuracy 0.2429\n",
      "Epoch 7 Batch 400 Loss 2.7548 Accuracy 0.2440\n",
      "Epoch 7 Batch 450 Loss 2.7469 Accuracy 0.2447\n",
      "Epoch 7 Batch 500 Loss 2.7406 Accuracy 0.2449\n",
      "Epoch 7 Batch 550 Loss 2.7331 Accuracy 0.2458\n",
      "Epoch 7 Batch 600 Loss 2.7281 Accuracy 0.2462\n",
      "Epoch 7 Batch 650 Loss 2.7231 Accuracy 0.2466\n",
      "Epoch 7 Batch 700 Loss 2.7179 Accuracy 0.2472\n",
      "Epoch 7 Loss 2.7178 Accuracy 0.2472\n",
      "Time taken for 1 epoch: 41.5109121799469 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 2.0792 Accuracy 0.2710\n",
      "Epoch 8 Batch 50 Loss 2.3923 Accuracy 0.2618\n",
      "Epoch 8 Batch 100 Loss 2.3911 Accuracy 0.2641\n",
      "Epoch 8 Batch 150 Loss 2.4023 Accuracy 0.2629\n",
      "Epoch 8 Batch 200 Loss 2.3945 Accuracy 0.2640\n",
      "Epoch 8 Batch 250 Loss 2.4008 Accuracy 0.2634\n",
      "Epoch 8 Batch 300 Loss 2.3961 Accuracy 0.2642\n",
      "Epoch 8 Batch 350 Loss 2.4007 Accuracy 0.2639\n",
      "Epoch 8 Batch 400 Loss 2.3979 Accuracy 0.2645\n",
      "Epoch 8 Batch 450 Loss 2.3978 Accuracy 0.2645\n",
      "Epoch 8 Batch 500 Loss 2.3970 Accuracy 0.2649\n",
      "Epoch 8 Batch 550 Loss 2.3924 Accuracy 0.2651\n",
      "Epoch 8 Batch 600 Loss 2.3916 Accuracy 0.2652\n",
      "Epoch 8 Batch 650 Loss 2.3911 Accuracy 0.2654\n",
      "Epoch 8 Batch 700 Loss 2.3885 Accuracy 0.2658\n",
      "Epoch 8 Loss 2.3882 Accuracy 0.2658\n",
      "Time taken for 1 epoch: 41.28891849517822 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 2.1815 Accuracy 0.2745\n",
      "Epoch 9 Batch 50 Loss 2.1284 Accuracy 0.2776\n",
      "Epoch 9 Batch 100 Loss 2.1296 Accuracy 0.2782\n",
      "Epoch 9 Batch 150 Loss 2.1388 Accuracy 0.2786\n",
      "Epoch 9 Batch 200 Loss 2.1412 Accuracy 0.2783\n",
      "Epoch 9 Batch 250 Loss 2.1444 Accuracy 0.2784\n",
      "Epoch 9 Batch 300 Loss 2.1414 Accuracy 0.2796\n",
      "Epoch 9 Batch 350 Loss 2.1400 Accuracy 0.2796\n",
      "Epoch 9 Batch 400 Loss 2.1434 Accuracy 0.2801\n",
      "Epoch 9 Batch 450 Loss 2.1454 Accuracy 0.2801\n",
      "Epoch 9 Batch 500 Loss 2.1464 Accuracy 0.2802\n",
      "Epoch 9 Batch 550 Loss 2.1446 Accuracy 0.2799\n",
      "Epoch 9 Batch 600 Loss 2.1454 Accuracy 0.2799\n",
      "Epoch 9 Batch 650 Loss 2.1498 Accuracy 0.2798\n",
      "Epoch 9 Batch 700 Loss 2.1508 Accuracy 0.2798\n",
      "Epoch 9 Loss 2.1511 Accuracy 0.2799\n",
      "Time taken for 1 epoch: 41.38485670089722 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.6685 Accuracy 0.3267\n",
      "Epoch 10 Batch 50 Loss 1.8969 Accuracy 0.2929\n",
      "Epoch 10 Batch 100 Loss 1.9263 Accuracy 0.2935\n",
      "Epoch 10 Batch 150 Loss 1.9366 Accuracy 0.2912\n",
      "Epoch 10 Batch 200 Loss 1.9477 Accuracy 0.2907\n",
      "Epoch 10 Batch 250 Loss 1.9530 Accuracy 0.2907\n",
      "Epoch 10 Batch 300 Loss 1.9525 Accuracy 0.2906\n",
      "Epoch 10 Batch 350 Loss 1.9518 Accuracy 0.2904\n",
      "Epoch 10 Batch 400 Loss 1.9553 Accuracy 0.2905\n",
      "Epoch 10 Batch 450 Loss 1.9553 Accuracy 0.2906\n",
      "Epoch 10 Batch 500 Loss 1.9601 Accuracy 0.2909\n",
      "Epoch 10 Batch 550 Loss 1.9641 Accuracy 0.2908\n",
      "Epoch 10 Batch 600 Loss 1.9661 Accuracy 0.2910\n",
      "Epoch 10 Batch 650 Loss 1.9690 Accuracy 0.2907\n",
      "Epoch 10 Batch 700 Loss 1.9729 Accuracy 0.2906\n",
      "Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-2\n",
      "Epoch 10 Loss 1.9732 Accuracy 0.2906\n",
      "Time taken for 1 epoch: 42.02320075035095 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 1.8104 Accuracy 0.3108\n",
      "Epoch 11 Batch 50 Loss 1.7475 Accuracy 0.3044\n",
      "Epoch 11 Batch 100 Loss 1.7595 Accuracy 0.3028\n",
      "Epoch 11 Batch 150 Loss 1.7678 Accuracy 0.3041\n",
      "Epoch 11 Batch 200 Loss 1.7806 Accuracy 0.3029\n",
      "Epoch 11 Batch 250 Loss 1.7907 Accuracy 0.3024\n",
      "Epoch 11 Batch 300 Loss 1.7972 Accuracy 0.3018\n",
      "Epoch 11 Batch 350 Loss 1.7999 Accuracy 0.3013\n",
      "Epoch 11 Batch 400 Loss 1.8034 Accuracy 0.3004\n",
      "Epoch 11 Batch 450 Loss 1.8085 Accuracy 0.3003\n",
      "Epoch 11 Batch 500 Loss 1.8140 Accuracy 0.2998\n",
      "Epoch 11 Batch 550 Loss 1.8184 Accuracy 0.2997\n",
      "Epoch 11 Batch 600 Loss 1.8228 Accuracy 0.2999\n",
      "Epoch 11 Batch 650 Loss 1.8268 Accuracy 0.3001\n",
      "Epoch 11 Batch 700 Loss 1.8290 Accuracy 0.2999\n",
      "Epoch 11 Loss 1.8293 Accuracy 0.2999\n",
      "Time taken for 1 epoch: 41.27653360366821 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 1.5276 Accuracy 0.3342\n",
      "Epoch 12 Batch 50 Loss 1.6305 Accuracy 0.3122\n",
      "Epoch 12 Batch 100 Loss 1.6416 Accuracy 0.3095\n",
      "Epoch 12 Batch 150 Loss 1.6563 Accuracy 0.3094\n",
      "Epoch 12 Batch 200 Loss 1.6656 Accuracy 0.3093\n",
      "Epoch 12 Batch 250 Loss 1.6710 Accuracy 0.3082\n",
      "Epoch 12 Batch 300 Loss 1.6773 Accuracy 0.3080\n",
      "Epoch 12 Batch 350 Loss 1.6817 Accuracy 0.3073\n",
      "Epoch 12 Batch 400 Loss 1.6876 Accuracy 0.3073\n",
      "Epoch 12 Batch 450 Loss 1.6909 Accuracy 0.3076\n",
      "Epoch 12 Batch 500 Loss 1.6928 Accuracy 0.3076\n",
      "Epoch 12 Batch 550 Loss 1.7008 Accuracy 0.3069\n",
      "Epoch 12 Batch 600 Loss 1.7048 Accuracy 0.3068\n",
      "Epoch 12 Batch 650 Loss 1.7082 Accuracy 0.3069\n",
      "Epoch 12 Batch 700 Loss 1.7130 Accuracy 0.3064\n",
      "Epoch 12 Loss 1.7132 Accuracy 0.3064\n",
      "Time taken for 1 epoch: 41.23147010803223 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 1.4846 Accuracy 0.3109\n",
      "Epoch 13 Batch 50 Loss 1.5374 Accuracy 0.3167\n",
      "Epoch 13 Batch 100 Loss 1.5411 Accuracy 0.3169\n",
      "Epoch 13 Batch 150 Loss 1.5540 Accuracy 0.3180\n",
      "Epoch 13 Batch 200 Loss 1.5655 Accuracy 0.3161\n",
      "Epoch 13 Batch 250 Loss 1.5715 Accuracy 0.3158\n",
      "Epoch 13 Batch 300 Loss 1.5785 Accuracy 0.3154\n",
      "Epoch 13 Batch 350 Loss 1.5823 Accuracy 0.3151\n",
      "Epoch 13 Batch 400 Loss 1.5853 Accuracy 0.3149\n",
      "Epoch 13 Batch 450 Loss 1.5893 Accuracy 0.3146\n",
      "Epoch 13 Batch 500 Loss 1.5915 Accuracy 0.3146\n",
      "Epoch 13 Batch 550 Loss 1.5967 Accuracy 0.3144\n",
      "Epoch 13 Batch 600 Loss 1.6035 Accuracy 0.3138\n",
      "Epoch 13 Batch 650 Loss 1.6105 Accuracy 0.3132\n",
      "Epoch 13 Batch 700 Loss 1.6133 Accuracy 0.3132\n",
      "Epoch 13 Loss 1.6132 Accuracy 0.3132\n",
      "Time taken for 1 epoch: 41.631065368652344 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 1.3161 Accuracy 0.3209\n",
      "Epoch 14 Batch 50 Loss 1.4270 Accuracy 0.3236\n",
      "Epoch 14 Batch 100 Loss 1.4348 Accuracy 0.3255\n",
      "Epoch 14 Batch 150 Loss 1.4567 Accuracy 0.3234\n",
      "Epoch 14 Batch 200 Loss 1.4619 Accuracy 0.3222\n",
      "Epoch 14 Batch 250 Loss 1.4713 Accuracy 0.3207\n",
      "Epoch 14 Batch 300 Loss 1.4824 Accuracy 0.3210\n",
      "Epoch 14 Batch 350 Loss 1.4895 Accuracy 0.3204\n",
      "Epoch 14 Batch 400 Loss 1.4946 Accuracy 0.3196\n",
      "Epoch 14 Batch 450 Loss 1.4993 Accuracy 0.3192\n",
      "Epoch 14 Batch 500 Loss 1.5054 Accuracy 0.3189\n",
      "Epoch 14 Batch 550 Loss 1.5121 Accuracy 0.3187\n",
      "Epoch 14 Batch 600 Loss 1.5187 Accuracy 0.3186\n",
      "Epoch 14 Batch 650 Loss 1.5221 Accuracy 0.3185\n",
      "Epoch 14 Batch 700 Loss 1.5269 Accuracy 0.3182\n",
      "Epoch 14 Loss 1.5271 Accuracy 0.3182\n",
      "Time taken for 1 epoch: 41.53741788864136 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 1.4735 Accuracy 0.3253\n",
      "Epoch 15 Batch 50 Loss 1.3796 Accuracy 0.3306\n",
      "Epoch 15 Batch 100 Loss 1.3809 Accuracy 0.3276\n",
      "Epoch 15 Batch 150 Loss 1.3896 Accuracy 0.3274\n",
      "Epoch 15 Batch 200 Loss 1.3963 Accuracy 0.3275\n",
      "Epoch 15 Batch 250 Loss 1.4050 Accuracy 0.3272\n",
      "Epoch 15 Batch 300 Loss 1.4084 Accuracy 0.3271\n",
      "Epoch 15 Batch 350 Loss 1.4139 Accuracy 0.3263\n",
      "Epoch 15 Batch 400 Loss 1.4174 Accuracy 0.3264\n",
      "Epoch 15 Batch 450 Loss 1.4237 Accuracy 0.3265\n",
      "Epoch 15 Batch 500 Loss 1.4292 Accuracy 0.3260\n",
      "Epoch 15 Batch 550 Loss 1.4354 Accuracy 0.3252\n",
      "Epoch 15 Batch 600 Loss 1.4416 Accuracy 0.3248\n",
      "Epoch 15 Batch 650 Loss 1.4476 Accuracy 0.3241\n",
      "Epoch 15 Batch 700 Loss 1.4532 Accuracy 0.3239\n",
      "Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-3\n",
      "Epoch 15 Loss 1.4532 Accuracy 0.3239\n",
      "Time taken for 1 epoch: 41.94780230522156 secs\n",
      "\n",
      "Epoch 16 Batch 0 Loss 1.4892 Accuracy 0.3072\n",
      "Epoch 16 Batch 50 Loss 1.3010 Accuracy 0.3401\n",
      "Epoch 16 Batch 100 Loss 1.3190 Accuracy 0.3368\n",
      "Epoch 16 Batch 150 Loss 1.3232 Accuracy 0.3356\n",
      "Epoch 16 Batch 200 Loss 1.3337 Accuracy 0.3349\n",
      "Epoch 16 Batch 250 Loss 1.3372 Accuracy 0.3335\n",
      "Epoch 16 Batch 300 Loss 1.3447 Accuracy 0.3326\n",
      "Epoch 16 Batch 350 Loss 1.3533 Accuracy 0.3322\n",
      "Epoch 16 Batch 400 Loss 1.3550 Accuracy 0.3319\n",
      "Epoch 16 Batch 450 Loss 1.3588 Accuracy 0.3320\n",
      "Epoch 16 Batch 500 Loss 1.3634 Accuracy 0.3316\n",
      "Epoch 16 Batch 550 Loss 1.3689 Accuracy 0.3306\n",
      "Epoch 16 Batch 600 Loss 1.3745 Accuracy 0.3301\n",
      "Epoch 16 Batch 650 Loss 1.3796 Accuracy 0.3297\n",
      "Epoch 16 Batch 700 Loss 1.3849 Accuracy 0.3292\n",
      "Epoch 16 Loss 1.3847 Accuracy 0.3292\n",
      "Time taken for 1 epoch: 41.17055344581604 secs\n",
      "\n",
      "Epoch 17 Batch 0 Loss 1.2141 Accuracy 0.3759\n",
      "Epoch 17 Batch 50 Loss 1.2455 Accuracy 0.3353\n",
      "Epoch 17 Batch 100 Loss 1.2536 Accuracy 0.3374\n",
      "Epoch 17 Batch 150 Loss 1.2621 Accuracy 0.3376\n",
      "Epoch 17 Batch 200 Loss 1.2633 Accuracy 0.3366\n",
      "Epoch 17 Batch 250 Loss 1.2678 Accuracy 0.3369\n",
      "Epoch 17 Batch 300 Loss 1.2733 Accuracy 0.3367\n",
      "Epoch 17 Batch 350 Loss 1.2806 Accuracy 0.3364\n",
      "Epoch 17 Batch 400 Loss 1.2877 Accuracy 0.3362\n",
      "Epoch 17 Batch 450 Loss 1.2931 Accuracy 0.3365\n",
      "Epoch 17 Batch 500 Loss 1.2975 Accuracy 0.3357\n",
      "Epoch 17 Batch 550 Loss 1.3051 Accuracy 0.3349\n",
      "Epoch 17 Batch 600 Loss 1.3102 Accuracy 0.3339\n",
      "Epoch 17 Batch 650 Loss 1.3169 Accuracy 0.3337\n",
      "Epoch 17 Batch 700 Loss 1.3236 Accuracy 0.3331\n",
      "Epoch 17 Loss 1.3238 Accuracy 0.3331\n",
      "Time taken for 1 epoch: 41.213239908218384 secs\n",
      "\n",
      "Epoch 18 Batch 0 Loss 1.1653 Accuracy 0.3480\n",
      "Epoch 18 Batch 50 Loss 1.2175 Accuracy 0.3413\n",
      "Epoch 18 Batch 100 Loss 1.2148 Accuracy 0.3408\n",
      "Epoch 18 Batch 150 Loss 1.2146 Accuracy 0.3397\n",
      "Epoch 18 Batch 200 Loss 1.2248 Accuracy 0.3399\n",
      "Epoch 18 Batch 250 Loss 1.2255 Accuracy 0.3403\n",
      "Epoch 18 Batch 300 Loss 1.2335 Accuracy 0.3398\n",
      "Epoch 18 Batch 350 Loss 1.2397 Accuracy 0.3398\n",
      "Epoch 18 Batch 400 Loss 1.2433 Accuracy 0.3397\n",
      "Epoch 18 Batch 450 Loss 1.2474 Accuracy 0.3394\n",
      "Epoch 18 Batch 500 Loss 1.2505 Accuracy 0.3393\n",
      "Epoch 18 Batch 550 Loss 1.2547 Accuracy 0.3390\n",
      "Epoch 18 Batch 600 Loss 1.2600 Accuracy 0.3386\n",
      "Epoch 18 Batch 650 Loss 1.2673 Accuracy 0.3381\n",
      "Epoch 18 Batch 700 Loss 1.2725 Accuracy 0.3376\n",
      "Epoch 18 Loss 1.2723 Accuracy 0.3375\n",
      "Time taken for 1 epoch: 41.271873474121094 secs\n",
      "\n",
      "Epoch 19 Batch 0 Loss 1.1996 Accuracy 0.3285\n",
      "Epoch 19 Batch 50 Loss 1.1332 Accuracy 0.3508\n",
      "Epoch 19 Batch 100 Loss 1.1437 Accuracy 0.3475\n",
      "Epoch 19 Batch 150 Loss 1.1563 Accuracy 0.3473\n",
      "Epoch 19 Batch 200 Loss 1.1677 Accuracy 0.3454\n",
      "Epoch 19 Batch 250 Loss 1.1775 Accuracy 0.3450\n",
      "Epoch 19 Batch 300 Loss 1.1809 Accuracy 0.3440\n",
      "Epoch 19 Batch 350 Loss 1.1868 Accuracy 0.3433\n",
      "Epoch 19 Batch 400 Loss 1.1899 Accuracy 0.3429\n",
      "Epoch 19 Batch 450 Loss 1.1939 Accuracy 0.3428\n",
      "Epoch 19 Batch 500 Loss 1.1970 Accuracy 0.3426\n",
      "Epoch 19 Batch 550 Loss 1.2041 Accuracy 0.3419\n",
      "Epoch 19 Batch 600 Loss 1.2107 Accuracy 0.3411\n",
      "Epoch 19 Batch 650 Loss 1.2164 Accuracy 0.3406\n",
      "Epoch 19 Batch 700 Loss 1.2212 Accuracy 0.3405\n",
      "Epoch 19 Loss 1.2216 Accuracy 0.3406\n",
      "Time taken for 1 epoch: 41.08094310760498 secs\n",
      "\n",
      "Epoch 20 Batch 0 Loss 1.0954 Accuracy 0.3585\n",
      "Epoch 20 Batch 50 Loss 1.1048 Accuracy 0.3533\n",
      "Epoch 20 Batch 100 Loss 1.1163 Accuracy 0.3490\n",
      "Epoch 20 Batch 150 Loss 1.1244 Accuracy 0.3486\n",
      "Epoch 20 Batch 200 Loss 1.1254 Accuracy 0.3484\n",
      "Epoch 20 Batch 250 Loss 1.1347 Accuracy 0.3469\n",
      "Epoch 20 Batch 300 Loss 1.1385 Accuracy 0.3466\n",
      "Epoch 20 Batch 350 Loss 1.1424 Accuracy 0.3468\n",
      "Epoch 20 Batch 400 Loss 1.1479 Accuracy 0.3461\n",
      "Epoch 20 Batch 450 Loss 1.1516 Accuracy 0.3453\n",
      "Epoch 20 Batch 500 Loss 1.1560 Accuracy 0.3452\n",
      "Epoch 20 Batch 550 Loss 1.1622 Accuracy 0.3448\n",
      "Epoch 20 Batch 600 Loss 1.1679 Accuracy 0.3444\n",
      "Epoch 20 Batch 650 Loss 1.1739 Accuracy 0.3439\n",
      "Epoch 20 Batch 700 Loss 1.1796 Accuracy 0.3437\n",
      "Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-4\n",
      "Epoch 20 Loss 1.1797 Accuracy 0.3436\n",
      "Time taken for 1 epoch: 41.77220034599304 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "  \n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  \n",
    "  # inp -> portuguese, tar -> english\n",
    "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "    train_step(inp, tar)\n",
    "    \n",
    "    if batch % 50 == 0:\n",
    "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "      \n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "    \n",
    "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QfcsSWswSdGV"
   },
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y6APsFrgImLW"
   },
   "source": [
    "모델 평가 순서는 다음과 같습니다.\n",
    "\n",
    "* 입력 문장 (포르투갈어)를 tokenizer를 이용해 쪼갭니다. 다음 start, end token을 문장 양 끝에 추가합니다.\n",
    "* decoder의 입력값은 start token입니다.\n",
    "* padding mask와 look ahead mask를 계산합니다.\n",
    "* `decoder`를 이용해 다음 단어 한 개를 예측합니다.\n",
    "* 예측한 단어 한 개를 decoder 입력값과 합치고 다시 `decoder`의 입력값으로 이용합니다.\n",
    "* 즉 이전 단어들을 이용해 다음 단어를 예측합니다. \n",
    "* end token이 나올때까지 이 과정을 반복합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5buvMlnvyrFm"
   },
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "  start_token = [tokenizer_pt.vocab_size]\n",
    "  end_token = [tokenizer_pt.vocab_size + 1]\n",
    "  \n",
    "  # inp sentence is portuguese, hence adding the start and end token\n",
    "  inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
    "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "  \n",
    "  # as the target is english, the first word to the transformer should be the\n",
    "  # english start token.\n",
    "  decoder_input = [tokenizer_en.vocab_size]\n",
    "  output = tf.expand_dims(decoder_input, 0)\n",
    "  \n",
    "  # MAX_LENGTH: 생성된 문장이 가질 수 있는 최대 길이\n",
    "  for i in range(MAX_LENGTH):\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "        encoder_input, output)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "    predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # 마지막 단어만 선택합니다. decoder 입력값으로 넣은 단어들과 예측한 다음 단어를 합치기 위해서입니다.\n",
    "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # end token이 생성되면 단어 생성을 멈추고 출력값으로 return합니다.\n",
    "    if predicted_id == tokenizer_en.vocab_size+1:\n",
    "      return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    # 마지막에 생성된 단어를 decoder의 입력값과 합칩니다. 이는 다음 루프의 decoder 입력값이 됩니다.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CN-BV43FMBej"
   },
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "  fig = plt.figure(figsize=(16, 8))\n",
    "  \n",
    "  sentence = tokenizer_pt.encode(sentence)\n",
    "  \n",
    "  attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "  for head in range(attention.shape[0]):\n",
    "    ax = fig.add_subplot(2, 4, head+1)\n",
    "    \n",
    "    # plot the attention weights\n",
    "    ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 10}\n",
    "    \n",
    "    ax.set_xticks(range(len(sentence)+2))\n",
    "    ax.set_yticks(range(len(result)))\n",
    "    \n",
    "    ax.set_ylim(len(result)-1.5, -0.5)\n",
    "        \n",
    "    ax.set_xticklabels(\n",
    "        ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
    "        fontdict=fontdict, rotation=90)\n",
    "    \n",
    "    ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                        if i < tokenizer_en.vocab_size], \n",
    "                       fontdict=fontdict)\n",
    "    \n",
    "    ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lU2_yG_vBGza"
   },
   "outputs": [],
   "source": [
    "def translate(sentence, plot=''):\n",
    "  result, attention_weights = evaluate(sentence)\n",
    "  \n",
    "  predicted_sentence = tokenizer_en.decode([i for i in result \n",
    "                                            if i < tokenizer_en.vocab_size])  \n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  \n",
    "  if plot:\n",
    "    plot_attention_weights(attention_weights, sentence, result, plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YsxrAlvFG8SZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: este é um problema que temos que resolver.\n",
      "Predicted translation: this is a problem that we have to deal with the growth of the city .\n",
      "Real translation: this is a problem we have to solve .\n"
     ]
    }
   ],
   "source": [
    "translate(\"este é um problema que temos que resolver.\")\n",
    "print (\"Real translation: this is a problem we have to solve .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7EH5y_aqI4t1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: os meus vizinhos ouviram sobre esta ideia.\n",
      "Predicted translation: my neighbors heard about this idea of the relationship .\n",
      "Real translation: and my neighboring homes heard about this idea .\n"
     ]
    }
   ],
   "source": [
    "translate(\"os meus vizinhos ouviram sobre esta ideia.\")\n",
    "print (\"Real translation: and my neighboring homes heard about this idea .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J-hVCTSUMlkb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\n",
      "Predicted translation: so i 'm going to just share with you some of some magic stories that happened .\n",
      "Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\n"
     ]
    }
   ],
   "source": [
    "translate(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\")\n",
    "print (\"Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_1MxkSZvz0jX"
   },
   "source": [
    "You can pass different layers and attention blocks of the decoder to the `plot` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t-kFyiOLH0xg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: este é o primeiro livro que eu fiz.\n",
      "Predicted translation: this is the first book that i did .\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real translation: this is the first book i've ever done.\n"
     ]
    }
   ],
   "source": [
    "translate(\"este é o primeiro livro que eu fiz.\", plot='decoder_layer4_block2')\n",
    "print (\"Real translation: this is the first book i've ever done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "s_qNSzzyaCbD"
   ],
   "name": "transformer.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
